{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from evaluate import load\n",
    "from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu\n",
    "import warnings\n",
    "\n",
    "os.chdir(\"..\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(ref, gen):\n",
    "    ''' \n",
    "    calculate pair wise bleu score. uses nltk implementation\n",
    "    Args:\n",
    "        references : a list of reference sentences \n",
    "        candidates : a list of candidate(generated) sentences\n",
    "    Returns:\n",
    "        bleu score(float)\n",
    "    '''\n",
    "    ref_bleu = []\n",
    "    gen_bleu = []\n",
    "    for l in gen:\n",
    "        gen_bleu.append(l.split())\n",
    "    for i,l in enumerate(ref):\n",
    "        ref_bleu.append([l.split()])\n",
    "    cc = SmoothingFunction()\n",
    "    score_bleu = corpus_bleu(ref_bleu, gen_bleu, weights=(0, 1, 0, 0), smoothing_function=cc.method4)\n",
    "    return score_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "def bert(ref, gen):\n",
    "    results = bertscore.compute(predictions=gen, references=ref, lang=\"en\")\n",
    "    return {metric: sum(scores)/len(scores) for metric, scores in results.items() if metric != \"hashcode\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      It is very common for people to have multiple ...\n",
       "1      Do you live with your mom and have constant in...\n",
       "2      When I'm working with men with this type of si...\n",
       "3      Hello, and thank you for your question and see...\n",
       "4      Give yourself a little more credit for self-ob...\n",
       "                             ...                        \n",
       "107    You are not alone.  SocIal media marketing is ...\n",
       "108    Staying present is an attitude most of us aspi...\n",
       "109    It sounds like your confused as to why your fr...\n",
       "110    Finding the right therapist for you is very im...\n",
       "111    It's more than just normal, it's expected! Qui...\n",
       "Name: answerText, Length: 112, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = pd.read_csv(\"data/processed/split/counsel-chat-best-answer-test.csv\")\n",
    "ref = ref.answerText\n",
    "ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      It's completely understandable that you have a...\n",
       "1      It's completely understandable that you don't ...\n",
       "2      I'm so sorry to hear that you're experiencing ...\n",
       "3      Sorry to hear that you're going through a diff...\n",
       "4      Sorry to hear that you're feeling alone and st...\n",
       "                             ...                        \n",
       "107    It's understandable to feel frustrated when yo...\n",
       "108    Great! Here are some suggestions for building ...\n",
       "109    I'm so sorry to hear that you're experiencing ...\n",
       "110    Great question! Finding the right therapist is...\n",
       "111    It is completely normal for people to cry duri...\n",
       "Name: generatedAnswerText, Length: 112, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_base = pd.read_csv(\"response/test-response-model_base_no_sys.csv\")\n",
    "gen_base = gen_base.generatedAnswerText\n",
    "gen_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029918555044600812\n",
      "{'precision': 0.8262056687048503, 'recall': 0.835644604904311, 'f1': 0.8308073596230575}\n"
     ]
    }
   ],
   "source": [
    "print(bleu(ref, gen_base))\n",
    "print(bert(ref, gen_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuned Llama-2-7B-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Thank you for sharing your personal struggles ...\n",
       "1      Thank you for reaching out for support. It's c...\n",
       "2      Thank you for reaching out for support. It tak...\n",
       "3      Thank you for sharing your struggles with me. ...\n",
       "4      Thank you for sharing your feelings with me. I...\n",
       "                             ...                        \n",
       "107    Thank you for reaching out with your concern. ...\n",
       "108    Of course! Building positive relationships in ...\n",
       "109    Thank you for reaching out with your concern. ...\n",
       "110    Thank you for reaching out with your question!...\n",
       "111    Hello there! It's completely normal for people...\n",
       "Name: generatedAnswerText, Length: 112, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_qlora = pd.read_csv(\"response/test-response-model_240411_0952.csv\")\n",
    "gen_qlora = gen_qlora.generatedAnswerText\n",
    "gen_qlora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0306515699220267\n",
      "{'precision': 0.8290465399622917, 'recall': 0.8361664499555316, 'f1': 0.8324928746691772}\n"
     ]
    }
   ],
   "source": [
    "print(bleu(ref, gen_qlora))\n",
    "print(bert(ref, gen_qlora))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG with Llama-2-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       It is not uncommon for individuals to have mu...\n",
       "1       It sounds like you are in a difficult situati...\n",
       "2       It's important to understand that erectile dy...\n",
       "3       It sounds like you are struggling with some p...\n",
       "4       It sounds like you are struggling with some d...\n",
       "                             ...                        \n",
       "107     It's possible that the people you are reachin...\n",
       "108     Of course! Having positive relationships in t...\n",
       "109     It is understandable to feel frustrated or up...\n",
       "110     Finding a good therapist is crucial for succe...\n",
       "111     It is completely normal for people to cry dur...\n",
       "Name: response, Length: 112, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_rag = pd.read_csv(\"response/test-response-llama2-7B-RAG.csv\")\n",
    "gen_rag = gen_rag.response\n",
    "gen_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03323976953759787\n",
      "{'precision': 0.8392691617565495, 'recall': 0.8385810325188296, 'f1': 0.8388241917959282}\n"
     ]
    }
   ],
   "source": [
    "print(bleu(ref, gen_rag))\n",
    "print(bert(ref, gen_rag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apai-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
